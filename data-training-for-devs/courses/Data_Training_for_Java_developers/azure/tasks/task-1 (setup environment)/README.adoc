= Task 1 - Infrastructure Setup
Dzmitry Marudau <dzmitry_marudau@epam.com>
1.0, October 22, 2024: Initial version from README.md
:toc:
:toclevels: 4
:icons: font
:url-quickref: https://docs.asciidoctor.org/asciidoc/latest/syntax-quick-reference/

> > *Time to complete*: 1 hour

== Objective
The goal of this task is to prepare Azure infrastructure by completing the following lessons. You will be provided with Terraform scripts that will set up all required components. In scope of this project you will be doing coding tasks mostly on top of an already created component just to avoid tedious and error-prone configuration part.

== Prerequisites
. Azure personal account or https://azure.microsoft.com/en-us/pricing/purchase-options/azure-account?icid=azurefreeaccount[Try Azure for free] if available.
. https://www.terraform.io/[Terraform] is installed locally on your machine.
. Java (at least version 17) is installed locally on your machine.
+
NOTE: You can use https://sdkman.io/[SDKMAN] to have different versions of Java SDK, Gradle and Mave
. https://maven.apache.org/download.cgi[Maven] is installed locally on your machine.
+
IMPORTANT:  It's required to be connected to VPN if you are working from Belarus.

. https://learn.microsoft.com/en-us/cli/azure/install-azure-cli[Azure CLI] is installed locally on your machine.
+
IMPORTANT:  If you are in Belarusian location, you might experience issue accessing terraform; hence VPN is required.

You can validate all tools required via following command:
[source,bash]
----
java --version && mvn --version && terraform --version && az --version
----

== Steps
. Compile and Build Azure Function to be used locally in the application.
- Navigate to `/materials/function` folder.
- Execute `mvn install` command.
- Make sure that `/materials/function/target/` folder contains compiled and built `function-1.0-SNAPSHOT.jar` file.

. Install environment.
- Navigate to `/terraform/azure` and open `terraform.tvars` file.
- Navigate to `/terraform/azure` folder and execute the following command: `terraform init`.
- Run `terraform plan` to review resources to be installed in your Azure subscription.
- In the same directory execute command: `terraform apply`. Print `yes` once requested.
- Installation might take some time, upon completion you will be provided with several endpoints, these are paths to studios you will be working from. They will look like:
+
[source,bash]
----
> databricks_studio_url = "https://adb-123456789.19.azuredatabricks.net"

> datafactory_studio_url = "https://adf.azure.com/en/home"

> synapse_studio_url = "https://web.azuresynapse.net?workspace=%2fsubscriptions%2f4d45zb6a-1310-f0g1-90c2-d82d4d3cbc5f%2fresourceGroups%2fbigdataaaec111lzix_rg%2fproviders%2fMicrosoft.Synapse%2fworkspaces%2fsynapse-workspace-bigdataaaec111lzix"
----

. After completion you will have core components being installed within your subscription. The picture below depicts main services.

image::../../materials/images/initial-infra-v1.png[Main services]

== Validation
Go to your Azure Subscription and validate that the following components were successfully deployed:

- Storage Account with *patient-data-source* folder inside
- Datalake storage with *bronze*, *silver* and *gold* folders inside.
- Azure Function that generates observation event. To check that events are being generated you might go to Event Hub and validate the *metrics/incoming messages*.
- Data Factory workspace with all required LinkedServices (storage account, datalake, key vault, databricks).
- Databricks workspace with default cluster being installed.  The cluster is of following shape:
> Single Node
> Standard_F4 shape
> 8 GB memory, 4 vCores
> 12.2.x-scala2.12 Runtime
> Automatic shutdown after 15 min inactivity
- Default notebooks with steps to complete will be uploaded to your Databricks workspace.
- Synapse Studio with default built-in Serverless SQL Pool.
- Stream Analytics Job.
